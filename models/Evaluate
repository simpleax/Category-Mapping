from sklearn import metrics

model = Model().to(device)

# 定义使用的loss和optimizer，这里支持自定义
model.compile(
    loss=nn.CrossEntropyLoss(),
    optimizer=optim.AdamW(model.parameters(), lr=2e-5),
    metrics=['acc'],   # 准确率accuracy
    metrics2=['pre'],  # 精确率precision
    metrics3=['rec'],  # 召回率rcall
    metrics4=['f1']    # f1分数
)


# 定义评价函数
def evaluate(data, mark):
    model.eval()
    total, right = 0., 0.
    pre = []
    gro = []
    for x_true, y_true in tqdm(data):
        y_pred = model.predict(x_true).argmax(axis=1)
        pre += y_pred.tolist()
        gro += y_true.tolist()
        total += len(y_true)
        right += (y_true == y_pred).sum().item()
    precise = metrics.precision_score(gro, pre)
    rec = metrics.recall_score(gro, pre)
    f1 = metrics.f1_score(gro, pre)
    print(f'{mark} precision: {precise:.5f}, recall: {rec:.5f}, f1: {f1:.5f}, acc: {right / total:.5f}')
    model.train()
    return right / total


class Evaluator(Callback):
    """评估与保存
    """

    def __init__(self):
        self.best_val_acc = 0.

    def on_epoch_end(self, global_step, epoch, logs=None):
        train_acc = evaluate(train_dataloader, "train")
        # print(f'train_acc: {train_acc:.5f}\n')
        test_acc = evaluate(test_dataloader, "test")
        if test_acc > self.best_val_acc:
            self.best_val_acc = test_acc
            model.save_weights('./BERT-RNN/best_model.pt')
        print(f'val_acc: {test_acc:.5f}, best_val_acc: {self.best_val_acc:.5f}\n')


if True:
    evaluator = Evaluator()
    model.fit(train_dataloader, epochs=20, callbacks=[evaluator])

